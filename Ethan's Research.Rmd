---
title: "Ethan's Project for Fall 2020"
author: "Ethan Tucker"
date: "June 26th, 2020"
output: html_document
---

ATTRIBUTION:
The data I use in this analysis were collected by Andrew Eckstrom of (?). Without this data none of the work that follows would have been possible. I also want to thank Professor Nordmoe for helping me with this project, from connecting me with the data set to all the helpful waychecks!

Potential error: Dataset does not distinguish between sections, so class tracker puts all sections together regardless of whether teaching quality and grade performance varied between sections.

Potential error: I can only track students \textit{once they have taken a math or chemistry course}. This is an issue for the first course analyses, because the students may have taken courses in prior terms in other departments.




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r Initialize}
library(readxl)
library(tidyverse)
library(merTools)
library(lme4)
Easy_Data <- read_excel("/home/local/KNET/k16et01/Homeworks/Research/Stats Research Math, Chemistry, and Biology Grades, Selected Courses.xlsx")
Gen_Data <- read_excel("/home/local/KNET/k16et01/Homeworks/Research/Stats Research XLS.xlsx")
set.seed(1000)


Gen_Data <- Gen_Data %>%
                  filter(`Student Random ID` != 649419)
```

ISSUE WITH DATA SET: THE EASY DATA TRACKER DOES NOT DIFFERENTIATE BETWEEN TYPES OF WITHDRAWS. Email Dr. Eckstrom?
ISSUE WITH DATA SET: HARD TO DIFFERENTIATE BETWEEN DIFFERENT SECTIONS Uni



GENDATA ANALYSIS (CHEMISTRY AND MATH STUDENTS)

```{r Gen_Data Semester Numbering, cache = TRUE}
##Fix Gen_Data semester listing. We want them listed numerically from 1 to N.

Number.Semesters <- function(x) {
  x <- x %>% arrange(Semester)
  
  individual.cases <- x %>% pull(Semester)
  
  individual.cases[1]
  
    for(y in seq_along(along.with = individual.cases)){
      if(individual.cases[y] == "2010/FA"){
        individual.cases[y] <- 1}
      else if(individual.cases[y] == "2011/WI"){
        individual.cases[y] <- 2}
      else if(individual.cases[y] == "2011/SU"){
        individual.cases[y] <- 3}
      else if(individual.cases[y] == "2011/FA"){
        individual.cases[y] <- 4}
      else if(individual.cases[y] == "2012/WI"){
        individual.cases[y] <- 5}
      else if(individual.cases[y] == "2012/SU"){
        individual.cases[y] <- 6}
      else if(individual.cases[y] == "2012/FA"){
        individual.cases[y] <- 7}
      else if(individual.cases[y] == "2013/WI"){
        individual.cases[y] <- 8}
      else if(individual.cases[y] == "2013/SU"){
        individual.cases[y] <- 9}
      else if(individual.cases[y] == "2013/FA"){
        individual.cases[y] <- 10}
      else if(individual.cases[y] == "2014/WI"){
        individual.cases[y] <- 11}
      else if(individual.cases[y] == "2014/SU"){
        individual.cases[y] <- 12}
      else if(individual.cases[y] == "2014/FA"){
        individual.cases[y] <- 13}
      else if(individual.cases[y] == "2015/WI"){
        individual.cases[y] <- 14}
      else if(individual.cases[y] == "2015/SU"){
        individual.cases[y] <- 15}
      else if(individual.cases[y] == "2015/FA"){
        individual.cases[y] <- 16}
      else if(individual.cases[y] == "2016/WI"){
        individual.cases[y] <- 17}
      else if(individual.cases[y] == "2016/SU"){
        individual.cases[y] <- 18}
      else if(individual.cases[y] == "2016/FA"){
        individual.cases[y] <- 19}
      else if(individual.cases[y] == "2017/WI"){
        individual.cases[y] <- 20}
      else{stop("There was an invalid Semester name passed to Number.Semesters")}
      }
    x <- mutate(x, Total.Term = individual.cases)
    x
  }
  
Gen_Data <- Number.Semesters(Gen_Data)
```


```{r}
##Total number of professors
Profs.List <- unique(Gen_Data$`Faculty Random ID`)
(n.p <- length(Profs.List))
##Total number of students
Students.List <- unique(Gen_Data$`Student Random ID`)
(n.s <- length(Students.List))
##Total quantity of course entries
n <- length(Gen_Data$`Course Code`)
```

```{r Gen_Data.Grade.Converter} 
##This chunk creates the GPA colunmn in Gen_Data
###Following grade converter obtained and adapted from stack overflow user A5C1D2H2I1M1N2O1R2T1 on the page https://stackoverflow.com/questions/22746508/r-simplifying-code-to-convert-letter-grades-to-numeric-grades on 8/19/2020

convert_grades <- function(x) {
    if (x == "WS") {
        x <- 0
    } else if (x == "WF"){
      x <- 0
    } else if (x == "W"){
      x <- NA
    } else if (x == "WP"){
      x <- NA
    } else if (x == "A") {
        x <- 4
    } else if (x == "A-") {
        x <- 3.7
    } else if (x == "B+") {
        x <- 3.3
    } else if (x == "B") {
        x <- 3
    } else if (x == "B-") {
        x <- 2.7
    } else if (x == "C+") {
        x <- 2.3
    } else if (x == "C") {
        x <- 2
    } else if (x == "C-") {
        x <- 1.7
    } else if (x == "D+") {
        x <- 1.3
    } else if (x == "D") {
        x <- 1
    } else if (x == "D-") {
        x <- 0.7
    } else if (x == "F") {
        x <- 0
    } else {
        x <- NA
    }
  x <- as.double(x)
    return(x)
}


## Fix broken data points
for(i in 1:n){
  if(Gen_Data$Grade[i] == "@D"){
    Gen_Data$Grade[i] <- "D"
  }
  if(Gen_Data$Grade[i] == "@F"){
    Gen_Data$Grade[i] <- "F"
  }
}

##Apply Grade Converter
Ass.GPA <- Gen_Data$Grade
Ass.GPA [] <- sapply(Ass.GPA, convert_grades)
Gen_Data <- mutate(Gen_Data, "GPA Assigned" = as.numeric(Ass.GPA))
```


```{r}
## Initialize Department in Gen_Data
Gen_Data <- Gen_Data %>%
                mutate(Department = str_sub(`Course Code`, 1, 3))
```

```{r Class Tracker Mean GPA Assigned and Delta, cache=TRUE}
##This chunk creates the Class Tracker, Mean GPA, and Delta columns in Gen_Data. This can be recreated nicely with dplyr, I'll do that if I have time.

##IMPORTANT NOTE: the new Gen_Data variable Class Mean GPA is calculated with na.rm = TRUE, and therefore it is the mean gpa assigned of those students who did not withdraw or take incompletes that did not get resolved.
##Initial Conditions
f <- 1
c <- 1
cntr <- 1
prv.cntr <- 0
Gen_Data <- mutate(Gen_Data, "Class Tracker" = NA, "Class Mean GPA" = NA, "Delta" = NA)
Gen_Data <- arrange(arrange(arrange(Gen_Data,`Faculty Random ID`),Semester),`Course Code`)

while(is.na(Gen_Data$`Class Tracker`[n])){
if(cntr == 4332){
  break
}
  
Current.Course.Name <- Gen_Data$`Course Code`[f]
Current.Semester <- Gen_Data$Semester[f]
Current.Professor <- Gen_Data$`Faculty Random ID`[f]

while(cntr != prv.cntr ){

  if(Gen_Data$`Course Code`[c] == Current.Course.Name && Gen_Data$Semester[c] == Current.Semester && Gen_Data$`Faculty Random ID`[c] == Current.Professor){
    Gen_Data$`Class Tracker`[c] <- cntr
    c <- c+1
    }
  
  else{
    ##Calculate class mean GPA and individual student Delta's
    Class.GPAS <- rep(0,c-f)
    for(z in 2:(c-f)){
      Class.GPAS[z] <- as.double(Gen_Data$"GPA Assigned"[z-1+f])
    }
     class.mean.gpa <- mean(Class.GPAS, na.rm = TRUE)
    
    for(k in f:(c-1)){
      Gen_Data$`Class Mean GPA`[k] <- class.mean.gpa
      Gen_Data$`Delta`[k] <- Gen_Data$"GPA Assigned"[k] - class.mean.gpa
    }
    prv.cntr <- prv.cntr + 1
  }
}

cntr <- cntr + 1

## c-f store to vector one known number of classes
f <- c
}

##There's some jank where this doesn't do the class gpa and delta for the final Class Tracker, so below I tell R to do it manually. This is terrible coding hide your dignity. My one thought was to add a dummy row at the end of Gen_Data and delete it after the loop, because I think R is stopping the loop as soon as the final Class Tracker is assigned, and completes neither Delta nor Class Mean GPA for the final class.
```

```{r}
##Rewrite above code chunk with dplyr if time allows
```

JANK:


```{r Fix final class}
##Fix final class from jank method
f <- 139171
l <- 139228
k <- l - (f-1)
Gen_Data <- arrange(arrange(arrange(Gen_Data,`Faculty Random ID`),Semester),`Course Code`)
Class.GPAS2 <- rep(0,k)
for(i in f:l){
  Class.GPAS2[i-(f-1)] <- as.double(Gen_Data$"GPA Assigned"[i])
  Gen_Data$`Class Tracker`[i] <- 4332 ##CHANGE
}
class.mean.gpa <- mean(Class.GPAS2,na.rm = TRUE)
for(i in f:l){
  Gen_Data$`Class Mean GPA`[i] <- class.mean.gpa
  Gen_Data$Delta[i] <- Gen_Data$"GPA Assigned"[i] - class.mean.gpa
}

```

```{r Initialize Student.Term, cache = TRUE}
##Here we convert Total.Term into numeric, and create the Student.Term variable which describes a student's term progression through OCC


Gen_Data <- Gen_Data %>%
              mutate(Total.Term = as.integer(Total.Term)) %>%
                arrange(`Student Random ID`, Total.Term) %>%
                  mutate(Student.Term = 0)

student.index <- function(cntr){
  student.id <- unique(Gen_Data$`Student Random ID`)[cntr]
  student.indecies <- which(Gen_Data$`Student Random ID` == student.id)
  return(student.indecies)
}
    
student.terms <- function(index){
  total.terms <- Gen_Data$Total.Term[index]
  student.terms <- rep(0, length(total.terms))
  last.total.term <- total.terms[1]
  student.terms[1] <- 1
  
  if(length(total.terms) >=2){
  
    for(i in 2:length(total.terms)){
      if(last.total.term == total.terms[i]){
        student.terms[i] <- student.terms[i-1]
      } else{
        last.total.term <- total.terms[i]
        student.terms[i] <- student.terms[i-1] + 1
      }
  }
    
  }
  return(student.terms)
}


##Use functions to assign student terms. This algorithm is very slow - I couldn't think of a better way to do it. It works, so it's good enough.
n.s <- length(unique(Gen_Data$`Student Random ID`))
Gen_Data2 <- Gen_Data %>%
              mutate(Student.Term = 0)
i <- 1
for(i in 1:n.s){
  Gen_Data2$Student.Term[student.index(i)] <- student.terms(student.index(i))
}
```

```{r}
##Create a new data frame that tracks individual students through their years at OCC. First we need to figure out how many classes a student takes in math/chem departments by term.

##Initialize Department 
Gen_Data3 <- Gen_Data2 %>%
              ungroup() %>%
                group_by(`Student Random ID`, `Class Tracker`) %>%
                  mutate(Department = str_sub(`Course Code`,1,3))

N.Math.By.Term <- Gen_Data3 %>%
                      group_by(`Student Random ID`, Student.Term, Department) %>%
                        count()

N.Math.By.Term %>%
  filter(n > 1) %>%
    ungroup() %>%
      rename(Num.Courses = n) %>%
        group_by(Department, Num.Courses) %>%
          count()

##This dataset can be used to show that students are much more likely to take n math courses simultaneously than n chemistry courses. Additionally, it tells us we need to make a robust points tracking algorithm. Student 28108 passed two math courses AND a chemistry course simultaneously (during student.term 3), which tells us that a student can take multiple courses per semester in the same department.
```

```{r}
##Create class size variable for statistical significance tests. There are 5 courses with iffy class sizes: 861, 2636, 3894, 4234, and 3148. The first four of these have n = 1 - they are independent studies. 3148 had n = 3, I'm not sure how that happened. Doing this filtration gives n >= 7, which will allow for safe usage of the t test. Fortunately we did not need to remove almost any cases, so validity of results is basically unaffected.
Sig.Courses <- Gen_Data3 %>%
                group_by(`Course Code`,`Class Tracker`) %>%
                  count() %>%
                      mutate(class_size = n, Significant = if_else(n > 5, TRUE, FALSE)) %>%
                        dplyr::select(-n) %>%
                         filter(Significant == TRUE)

Gen_Data4 <- left_join(Sig.Courses, Gen_Data3, by = c("Class Tracker", "Course Code")) %>%
              dplyr::select(-Significant)
```

```{r Max Terms}
##Initialize Max Terms variable in Gen_Data
Max_terms <- Gen_Data4 %>%
        arrange(`Student Random ID`, Student.Term) %>%
                group_by(`Student Random ID`) %>%
                                summarise(`Class Tracker` = `Class Tracker`, max.terms = max(Student.Term),  Student.Term = Student.Term, Delta = Delta, `Course Code` = `Course Code`, `Faculty Random ID` = `Faculty Random ID`)

Gen_Data5 <- left_join(Gen_Data4, Max_terms)
```



```{r Initialize.Points.Tracker}
##Creates Points Tracker
  
Gen_Data5 %>%
  group_by(`Class Tracker`) %>% 
    summarise(Prof = head(`Faculty Random ID`, n = 1))
  
Points.Tracker <- data.frame(Prof.Type = NA, Professors = Profs.List, First.Math.Points = 0, First.Chem.Points = 0, First.Bio.Points = 0, First.Withdraw.Prop = 0,  Total.Math.Points = 0, Total.Chem.Points = 0, Total.Bio.Points = 0,  Total.Withdraw.Prop = 0, Future.Withdraw.Prop = 0, Total.Students = 0)
Points.Tracker <- arrange(Points.Tracker, `Professors`)
```

```{r Course Credits}
##In order to create cumulative GPA we need to weight by credit hours. This chunk creates a credit variable for each row in Gen Data

##Found CHE-0950 credits at https://www.oaklandcc.edu/finaid/docs/fa39a_satisfactoryacademic.pdf . I could not find the name, so I'm calling it preparation for chemistry because it is high school level chemistry according to https://wmich.edu/sites/default/files/attachments/u684/2016/Chemistry-%20Oakland%20CC_0.pdf  
##Found MAT-1045 credits at https://www.oaklandcc.edu/schedule/docs/OCC_Schedule_2017_WI.pdf
#Found MAT-1140 credits at http://dalnetarchive.org/bitstream/handle/11061/1402/2007%20Mathematics-%20Curriculum%20Review%20Self%20Study.pdf?sequence=1&isAllowed=y
Course.Credits <- tibble(`Course Code` = unique(Gen_Data4$`Course Code`),
                  `Course Credits` =  c(4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4 , 4 , 3, 4, 4, 4, 4, 3, 4, 4, 5, 4),
                    `Course Names` = c("Preparation for Chemistry", "Introductory Chemistry", "Survey of Organic and Biochemistry", "General Chemistry I", "General Chemistry II", "Organic Chemistry I", "Organic Chemistry II", "Organic Chemistry Lab", "Fundamentals of Arithmetic", "Preparation for Algebra", "Buisness Mathematics", "Elementary Algebra", "Math Literacy", "Plane Geometry", "Intermediate Algebra", "Finite Mathematics", "Quantitative Reasoning", "College Algebra", "Trigenometry", "Statistics", "Applied Calculus", "Precalculus", "Calculus I"))


Gen_Data6 <- Gen_Data5 %>%
                left_join(Course.Credits, by = "Course Code")
```

```{r Cumulative GPA, warning = FALSE}
## This chunk creates the cumulative GPA variable in Gen_Data. This allows us to track our students through OCC without having such a stratified model - cumulative GPA is much less discrete than GPA Assigned.

##This first section creates the Cum.GPA variable with a simple weighted mean in a dummy dataset which will eventually be stored as Gen_Data
No_Withdraws <- Gen_Data6 %>%
                        arrange(`Student Random ID`, Student.Term) %>%
                                filter(!is.na(`GPA Assigned`)) %>%
                                        mutate(Cum.GPA = 0)
current.numerator <- 0
current.denominator <- 0
current.student <- 31
n.w <- length(No_Withdraws$`GPA Assigned`)
for(i in 1:n.w){
        if(No_Withdraws$`Student Random ID`[i] != current.student){
                current.numerator <- 0
                current.denominator <- 0
                current.student <- No_Withdraws$`Student Random ID`[i]
        }
        current.numerator <- current.numerator + No_Withdraws$`GPA Assigned`[i] * No_Withdraws$`Course Credits`[i]
        current.denominator <- current.denominator + No_Withdraws$`Course Credits`[i]
        
        No_Withdraws$Cum.GPA[i] <- current.numerator / current.denominator
                
}


Temp_Data <- Gen_Data6 %>%
                left_join(No_Withdraws) %>%
                        arrange(`Student Random ID`, Student.Term)


##This second section assigns the previous Cum.GPA to all withdraws if the student had a previous Cum.GPA. This allows for better visualization in ggplot, and better modeling with lmer.

for(i in 2:n){
        current.student <- Temp_Data$`Student Random ID`[i]
        previous.student <- Temp_Data$`Student Random ID`[i-1]
        
        if(is.na(Temp_Data$Cum.GPA[i])){
                if(current.student == previous.student){Temp_Data$Cum.GPA[i] <- Temp_Data$Cum.GPA[i-1] }
        }
}
```

```{r Initialize Cum.GPA}
##Here we store Cum.GPA into Gen_Data
Gen_Data7 <- Temp_Data
```

```{r No muli-department faculty}
## This chunk shows that there are no faculty that teach in both the math and chemistry departments.
counter <- Gen_Data7 %>%
              group_by(`Faculty Random ID`, Department) %>%
                count() 
length(counter$`Faculty Random ID`) - length(unique(Gen_Data6$`Faculty Random ID`))
```


```{r}
##Determine course difficulty by average GPA assigned to those who did not withdraw. Proportion of withdraws by course code is represented in future section.
Course.GPAs <- Gen_Data7 %>%
                 ungroup() %>%
                    group_by(`Course Code`) %>%
                      summarise(Course.Code.Mean.GPA = mean(Cum.GPA, na.rm = TRUE))

Gen_Data8 <- Gen_Data7 %>%
              left_join(Course.GPAs, by = "Course Code") %>% View()
```








Questions:

1) Does the professor a student encounters first in a department influence future performance in department / out of department? Are some faculty better at teaching some courses than others?


  As the below graph shows, it is impossible to create an inference for this question on the entire data set. Some students withdraw from their courses in the first term and thus do not receive grades - it is impossible to analyze their GPA assigned in the first term. We can however measure probability of success by filtering for only those students that withdrew from courses in the first term, and those who did not. This brings us to a second issue - the data we have are only for the courses that students took in the math and chemistry departments during their stay at OCC. We cannot with any degree of certainty claim that those first recorded terms in the dataset are indeed the first terms. Student X could have taken an English course in a term before appearing in our data set for all we know. We have implicitly filtered for: (1) students who did not for some reason attend a standard four year college, and (2) students that wished to take math and/or chemistry courses in community college. We have moreover restricted our departmental information to only chemistry and mathematics courses, which removes our ability to deal with the possibility that the math or chemistry departments are outliers in this question. Alas, let's do our best.
  
```{r, warning=FALSE}
##Create plot to illustrate the inability to use all students for Q1. We must then do a filtration!
Plot.Data1 <- Gen_Data8 %>%
                group_by(`Student Random ID`) %>%
                  slice(1) %>%
                    mutate(First.Term.Withdraw = if_else(is.na(Cum.GPA), "Yes", "No")) %>%
                      dplyr::select(`Student Random ID`, First.Term.Withdraw, `Class Tracker`) %>%
                        right_join(Gen_Data8, by = c("Student Random ID"))

Plot.Data1 %>% 
    filter(`Student Random ID` <= 10^3) %>%
        ggplot(aes(x = Student.Term, y = Cum.GPA, group = factor(`Student Random ID`), color = First.Term.Withdraw)) +
        geom_point(position = position_jitter(width = 0.2, height = 0.1)) + 
        geom_smooth(method = "lm", se = FALSE) + 
        labs(x = "Student's Term", y = "Cumulative GPA", title = "Cumulative GPA by Student's Term for 178 Randomly Selected Students", color = "Did student withdraw from first course?")
```
6 out of the total 178 randomly drawn students withdrew from their first course. The GPA they were assigned in their second term cannot be considered an accurate substitute, because the question specifically regards the $\textit{experience}$ a student had in their first exposure to community college mathematics or chemistry. To partially answer this question, we must then first filter for all students that took only one course in their first term, did not withdraw from that first course, and took at least two terms total. By mandating these conditions we invariably reduce our sample size, but because our dataset is so large and the conditions rather lenient at this stage we expect no issue. In particular, after this filtration we are left with $35687$ unique students distributed over $267$ unique faculty members. The mean faculty member then will contribute to $\sim 133.66$ measurable outcomes using this scheme - well over the $30 \sim 40$ that is standard guidance for utilizing the $Z$ test statistic .

```{r}
##Initialize number of courses per term,  filter for those students that took only one course in their first term and took at least two terms in the math or chemistry departments. That is, math first term then chemistry second term is totally legal.
Course.Num <- Gen_Data8 %>%
                group_by(`Student Random ID`, Student.Term) %>%
                  count() %>%
                    right_join(Gen_Data8, by = c("Student Random ID", "Student.Term")) %>%
                      rename(Num.Courses.In.Term = n) %>%
                        filter(max.terms >= 2, Num.Courses.In.Term*Student.Term == 1)



##Initialize First Prof and First Course
Gen_Data9 <- Course.Num %>%
              mutate(First.Prof = `Faculty Random ID`, First.Course = `Course Code`) %>%
                ungroup() %>%
                  dplyr::select(First.Prof, `Student Random ID`, First.Course) %>%
                    right_join(Gen_Data8, by = c("Student Random ID"))


##Number of remaining unique students after filtration, and number of unique faculty
length(unique(Gen_Data$`Student Random ID`)) - length(unique(Gen_Data9$`Student Random ID`[!is.na(Gen_Data9$First.Prof)]))
length(unique(Gen_Data9$`Faculty Random ID`))

##Filter for students that did not withdraw from first course
Not.First.Withdraw <- Gen_Data9 %>%
               ungroup()%>%
                  group_by(`Student Random ID`) %>%
                    slice(1) %>%
                      filter(Student.Term == 1, !is.na(`GPA Assigned`), !is.na(First.Prof)) %>%
                        dplyr::select(`Student Random ID`)

Filtered.Data1 <- Gen_Data9 %>%
                    semi_join(Not.First.Withdraw, by = "Student Random ID")

##Show that there are no entries of Filtered.Data1 that have an NA value for First.Prof - that is we have successfully chosen only those students who did not withdraw from their first course
length(Filtered.Data1$First.Prof[is.na(Filtered.Data1$First.Prof)])
```

Here we have created a variable in Gen_Data that tracks the first professor a student had.   

We can represent the mean student's path through OCC using a linear mixed-effects model. At the time of my writing this, the package lme4 was the most current mixed modeling package available through CRAN. (CITE) A linear mixed-effects model represents a dependent variable - in our case the cumulative GPA of a student - as a linear function of some inputs. The benefit of using such a model is that instead of just using a fixed effect as predictor, such as the student's term number, we can manually specify certain variables to lme4 that either effect the intercept or the slope of our linear model. One possible covariant effect to future cumulative GPA achievement may be the course in which students begin their tenure at OCC's math/chemistry departments. For instance - there may be a difference in both the starting GPA and the slope for cumulative GPA in the mean student that begins their community college math courses in Preparation for Algebra (MAT - 1050) and a student that began in Calculus II (Mat - 1740). Before we can appropriately analyze the effect that individual professors of these courses have on students that begin in these courses, we need to first determine the mean case for all these courses. The below chunk employs lme4 to create a linear mixed-effects model for each course using only those students that: (1) did not withdraw from the course in their first term so that we have a measurable GPA intercept, and (2) took more than one course in the data set so that we can generate a slope between two observations.  An alternative to assumption (1) is to allow students to withdraw from their first course, but in this case it becomes impossible to gauge how their course experience was based on cumulative gpa. We will look at proportion of withdraws against the mean for each course as an additional metric of professor effect later.

```{r}
## Find those courses that affect a students future cumulative GPA slope as a function of term.

courses <- unique(Filtered.Data1$`Course Code`)


## These models predict a student's Cumulative GPA in the math and chemistry departments during their stay at OCC depending on the course they took first. This 
make.course.model <- function(course){
  One.Course.Data <- Filtered.Data1 %>%
                      filter(First.Course == course)
    if(length(One.Course.Data$`Student Random ID`) > 29){
      Cum.course.model <- lmer(Cum.GPA ~ Student.Term + (1|`Student Random ID`), data = One.Course.Data)
      return(summary(Cum.course.model)$coefficients)
  } else{return(str_c("Insufficient students started at OCC in ",course, " to create an accurate model (minimum 30, observed ", length(One.Course.Data$`Student Random ID`), ")",   sep = ""))}
}

course.summaries <- sapply(courses, make.course.model)


##This function pulls those courses with a significant positive impact on future cumulative gpa
sig.summaries.positive <- function(list){
  Sig.Courses.Positive <- rep("Remove", length(list))
  for(i in 1:length(list)){
    if(!is.null(dim(course.summaries[[i]]))){
    intercept.tval <- list[[i]][1,3]
    Student.Term.tval <- list[[i]][2,3]
      if(intercept.tval >= qnorm(0.95) & Student.Term.tval >= qnorm(0.95)){
        Sig.Courses.Positive[i] <- names(course.summaries[i])
    }
    }
  }
  return(Sig.Courses.Positive[Sig.Courses.Positive != "Remove"])
}

## And this is a function that extracts those courses that have a significant negative effect on future GPA
sig.summaries.negative <- function(list){
  Sig.Courses.Negative <- rep("Remove", length(list))
  for(i in 1:length(list)){
    if(!is.null(dim(course.summaries[[i]]))){
    intercept.tval <- list[[i]][1,3]
    Student.Term.tval <- list[[i]][2,3]
      if(intercept.tval >= qnorm(0.95) & Student.Term.tval <= qnorm(0.05)){
        Sig.Courses.Negative[i] <- names(course.summaries[i])
    }
    }
  }
  return(Sig.Courses.Negative[Sig.Courses.Negative != "Remove"])
}


##These vectors contain all the courses that had significant effects on future cumulative GPA.
significant.courses.positive <- sig.summaries.positive(course.summaries)
significant.courses.negative <- sig.summaries.negative(course.summaries)

##These are the courses that did not have enough students begin in them to use the approximate Z test statistic for estimation of future cumulative GPA
not.enough.data <- rep("remove", length(course.summaries))
for(i in 1:length(course.summaries)){
  if(is.null(dim(course.summaries[[i]]))){
    not.enough.data[i] <- names(course.summaries[i])
  }
}
not.enough.data <- not.enough.data[not.enough.data != "remove"]

## Finally, these are the courses that did have enough data to use the approximate Z test statistic but did not significantly influence future cumulative GPA. Students that began in these courses will be compared to the global mean.
`%notin%` <- Negate(`%in%`)
not.significant <- courses[courses %notin% significant.courses.positive & courses %notin% significant.courses.negative & courses %notin% not.enough.data]

## Tibble used to calculate mean number of courses taught by faculty for following paragraph.
Prof.Courses <-  Filtered.Data1 %>%
                    ungroup() %>%
                      group_by(`Faculty Random ID`, `Course Code`) %>%
                        count() %>%
                          dplyr::select(-n) %>%
                            ungroup() %>%
                              group_by(`Faculty Random ID`) %>%
                                summarise(Num.Courses.Taught = n())
```
For brevity I will refer to individual courses by their course code, but I have included a lookup table at the end of this document that includes course name and the number of credits for those interested. The courses that had a significant positive effect on future cumulative GPA were `r significant.courses.positive`. The courses that had a significant negative effect on future cumulative GPA were `r significant.courses.negative`. There are two categories of non-significant courses: those in which an insufficient number of students started to draw a proper inference (I used n >= 30), and those which had sufficient data but whose students' GPAS did not follow a statistically significant common pattern using $\alpha = 0.01$. The courses that did not have enough students start in them for analysis were `r not.enough.data`. The courses that had enough students take them first but did not significantly effect future cumulative GPA were `r not.significant`.

To obtain a model of professor influence on future cumulative GPA, we first filter out all those students that begain in courses that did not have enough data to provide inference. This is a source of error in the analysis: there may or may not be a significant effect on future cumulative gpa for those students that began in these courses, but we would need more data to be confident. It is therefore inappropriate to superimpose the mean student's cumulative gpa progression onto the students who took these courses. We therefore cannot measure the future effects of the professors that taught such courses - this may be a big error because on average faculty only teach `r mean(Prof.Courses$Num.Courses.Taught)` different courses. On the other hand, it $\textit{is}$ appropriate to superimpose the mean onto those students whose first math or chemistry course was in the list `r not.significant`. The students whose first class had a significant effect on their outcome will be measured against their peers.

We now begin working towards building vectors for each professor that contain the change in cumulative GPA for all students from first to final term in $\textit{both}$ the mathematics and chemistry departments. We will then take the difference between this change and the expected change as predicted by our linear mixed effects models (we have adjusted for the slope and intercepts effects caused by course). This is a measure of student outcome. We have then refined our question to: how does the professor an OCC student have first in the math or chemistry department affect that student's final performance in those departments? Outside of those departments? After creating this distribution we will test for significant effects two ways. First we will use a standard one sample t-test, obtaining the degrees of freedom from the number of students that started with that faculty member minus one. We will also bootstrap the values to create a model of the sampling distribution, then create a confidence interval to compare against the mean outcome. All professors with a statistically significant $\texit{positive}$ effect on student outcomes as compared to the mean student adjusted for course will be categorized as "good", and likewise those with significant $\textit{negative}$ effects will be categorized as "poor". Based on our choice for $\alpha$ we expect some error - there should be approximately $M = \alpha * n_{prof}$ misclassifications. If M is not so different from the sum of the numbers of "good" and "poor" professors, we will be confident that there is little real variance in the effect professors have on students (in the math and chemistry departments of OCC).


```{r Strata Justification}
##Create overall visualization of final cumulative GPA by first course
Filtered.Data1 %>%
  ungroup() %>%
    group_by(`Student Random ID`) %>%
      slice(n()) %>%
        filter(max.terms >= 2) %>%
          dplyr::select(Cum.GPA, `Student Random ID`) %>%
            rename(Last.Term.Cum.GPA = Cum.GPA) %>%
              right_join(Filtered.Data1) %>%
                left_join(Course.Heights, by = "Course Code") %>%
                  group_by(`Student Random ID`) %>%
                    slice(n()) %>%
                      ungroup() %>%
                        ggplot() +
                        geom_boxplot(aes(x = Last.Term.Cum.GPA, color = `First.Course`)) +
                        labs(x = "Last Term Cumulative GPA", color = "First Course", title = "Boxplots of Final Cumulative GPA for all Students that did not\nWithdraw from their First Course, colored by First Course")

```

As can be seen in the above boxplot, the students that begin in each possible course have inherently different final cumulative GPA distributions. We must then account for this discrepancy when determining the effects that the first professor has on cumulative GPA. We wish to create a linear mixed-effects model that accounts for the projection of future cumulative GPA imparted by the first course a student takes. To do so, we will split students into strata by first course. The courses that have at least 30 students start in it will be ruled sufficient to create a reasonable projection for the mean student. For each student, the increase/decrease per term predicted by the germane linear mixed-effects model will be multiplied by the number of terms the student enrolled in math/chemistry courses at OCC, and added to the initial observation of cumulative GPA - this is the expected outcome. The performance of a student will then be judged by comparing their observed final cumulative GPA to the expected outcome.  In the following chunk we will build these stratified models, and create a statistic called $\Delta 2$ which is the aforementioned difference between observed and expected outcome. A positive $\Delta 2$ implies that the student's final cumulative GPA exceeded the prediction by the linear mixed effects model. I would like to note that the slope predicted by a linear mixed model will be a constant over the entire stratum. As such, a student that scores a $4.0$ GPA in their first course where the course slope was positive will never be able to meet expectations by the model, and so will erroneously have a negative $\Delta 2$ score even if they score straight A's in each math and chemistry course they take at OCC. Similarly, a student that fails the first course with a negative slope cannot obtain a negative $\Delta 2$ score. These errors will be largely outweighed by students that score in the middle in the first course, but are important to note. As we will see briefly, the overall error for the mean student in all strata is around $0.01$ GPA points, and so the models are collectively quite good. Later, we will examine alternate statistics for ranking professor influence that are more error adverse, namely withdraw rate and the number of future courses taken (adjusted for stratum).

```{r Create Delta2 Models}
## Create course - specific models of Cum.GPA progression through student's stay at OCC in Filtered.Data using Cum.GPA as a predictor. First, obtain a confidence interval for the effect of Student.Term on the mean student for superposition onto those courses that had a measurable non-significant deviation from the mean effect on student.term.

##Overall model for students 
Cum.lmer.model2 <- lmer(Cum.GPA ~ Student.Term + (1|`Student Random ID`), data = Filtered.Data1)

## Determine the first observation of GPA for each student, then use it as the intercept for the mean linear mixed effects model
First.Course.GPA <-  Filtered.Data1 %>%
                      ungroup() %>%
                        group_by(`Student Random ID`) %>%
                          slice(1) %>%
                            mutate(First.Course.GPA = Cum.GPA) %>%
                              dplyr::select(`Student Random ID`, First.Course.GPA)

## Store mean mixed effects model predictions to Filtered.Data
Filtered.Data2 <- Filtered.Data1 %>%
                    left_join(First.Course.GPA, by = "Student Random ID")
           
##  Store student's last term cumulative GPA to a variable in Filtered.Data for error analysis (the error is what will get bootstrapped) 
Filtered.Data3 <- Filtered.Data2  %>%
                    ungroup()%>%
                      group_by(`Student Random ID`) %>%
                        slice(n()) %>%
                          mutate(Last.Term.Cum.GPA = Cum.GPA) %>%
                            dplyr::select(`Student Random ID`, Last.Term.Cum.GPA) %>%
                              right_join(Filtered.Data2, by = "Student Random ID")

##First need to create tibble containing the variables (1) Course Code, (2) LMER slope for all courses that had a significant effect. If the course had no significant effect the slope will be the mean slope defined in the previous chunk.
n.courses <- length(unique(Filtered.Data3$`Course Code`))
course.slopes <- tibble(First.Course = unique(Filtered.Data3$`Course Code`), 
                        Course.LMER.slope = rep(0, n.courses))

## Grab lmer slopes for significant courses
set.sig.Course.LMER.Slopes <- function(list){
  
  temp.course.slopes <- course.slopes
  
  for(i in list){
    course.slope <- course.summaries[[i]][2,1]
    temp.course.slopes$Course.LMER.slope[temp.course.slopes$First.Course == i] <- course.slope
  }
  return(temp.course.slopes)
}

course.slopes <- set.sig.Course.LMER.Slopes(significant.courses.positive)
course.slopes <- set.sig.Course.LMER.Slopes(significant.courses.negative)

##Superimpose mean onto those courses that had at least 30 observations, but did not have significant deviation from the mean 

set.mean.Course.LMER.Slopes <- function(list){
  
  temp.course.slopes <- course.slopes
  
  for(i in list){
    course.slope <- summary(Cum.lmer.model2)$coefficients[2,1]
    temp.course.slopes$Course.LMER.slope[temp.course.slopes$First.Course == i] <- course.slope
  }
  return(temp.course.slopes)
}

course.slopes <- set.mean.Course.LMER.Slopes(not.significant)

## Remove non significant courses for upcoming semi-join, then join back to filtered data.
course.slopes <- course.slopes %>%
                    filter(Course.LMER.slope != 0)

##Join significant courses slopes back onto Filtered.Data  
Filtered.Data4 <- Filtered.Data3 %>%
                    semi_join(course.slopes, by = "First.Course") %>%
                      left_join(course.slopes, by = "First.Course")

## Determine difference between expected and observed final cumulative GPA in Delta2, and rejoin into Filtered.Data
Filtered.Data5 <- Filtered.Data4 %>% 
                    filter(Student.Term == max.terms) %>%
                      mutate(LMER.Predict = First.Course.GPA + Course.LMER.slope*max.terms) %>%
                        mutate(Delta2 = Last.Term.Cum.GPA - LMER.Predict) %>%
                          dplyr::select(`Student Random ID`, Delta2) %>%
                            right_join(Filtered.Data4, by = c("Student Random ID"))
```

There are the $19$ remaining courses after filtration, using the requirement that a valid course have at least 30 students begin in it. Here we have created a dataframe consisting of only those students whose mean course effect on future cumulative gpa was measurable - significant or not. For these students we have measured the difference between their final cumulative GPA in the math and chemistry department and the expected final cumulative GPA adjusted for starting course. We will now assign these $\Delta 2$ values to the student's first professor, then create several graphs using this statistic. We will furthermore differentiate between the significant mean effects that faculty had on future cumulative GPA and those that we have insufficient data to obtain an accurate estimate for.

```{r Assign Prof Delta2s}
##Assign general points

##Represent the Mean Delta2 values for all professors
Delta2.Data <- Filtered.Data5 %>% 
                ungroup() %>%
                  group_by(`Student Random ID`) %>%
                    slice(n()) %>%
                      ungroup() %>%
                          dplyr::select(`Student Random ID`, Delta2, First.Prof)

head(Delta2.Data,5)

##Create sample size column for t test, and standard error
Delta2.Data2 <- Delta2.Data %>%
                group_by(First.Prof) %>%
                  summarise(Mean.Delta2 = mean(Delta2), sample.size = n(), standard.error = sd(Delta2)/n())

## Find overall mean of Delta2. If there is no residual error in our model, this value should be precisely zero. 
overall.mean.Delta2 <- Delta2.Data2 %>%
                    mutate(Net.Delta = Mean.Delta2 * sample.size) %>%
                      pull(Net.Delta) %>%
                        sum()/sum(Delta2.Data2$sample.size)

## T test procedure found at https://libguides.library.kent.edu/SPSS/OneSampletTest
## Carry out t test for those faculty members that had at least 
Delta2.Data3 <- Delta2.Data2 %>%
                  filter(sample.size >= 3) %>%
                    mutate(requisite.tval = qt(0.95, sample.size-1), observed.tval = abs((Mean.Delta2-overall.mean.Delta2))/standard.error) %>%
                     mutate(significant = if_else(observed.tval > requisite.tval, TRUE, FALSE, FALSE), Prof.Quality = if_else(Mean.Delta2 > overall.mean.Delta2, "Good", "Poor"))
tail(Delta2.Data3, 6)

##Determine Faculty quality for those professors that had significant effects on future cumulative gpa
Prof.Qualities <- Delta2.Data3 %>%
  filter(significant == TRUE) %>%
      pull(Prof.Quality)

# length(Prof.Qualities) is the total number of faculty that had significant effect on future cumulative GPA
# length(Prof.Qualities[Prof.Qualities == "Good"]) is the total number of faculty that had significant positive effect on future cumulative GPA. This number can be subtracted from the line above to find total number of faculty that had significant negative effect on future cumulative GPA.
```

The significance test I have just ran employs the statistic $\Delta 2$, which is calculated as a student's final cumulative GPA minus the final cumulative GPA predicted by the germane of the . That is, $\Delta 2$ is the deviation of an individual student's final cumulative GPA from the mean final cumulative GPA of those students that began in the same course (e.g. Trigonometry). I will interchangeably refer to this statistic as $\Delta 2$.

The overall error in our course-corrected linear mixed-effects model after all filtration is $0.01047$ GPA points, with mean standard errors  . That is, if the linear mixed-effects model perfectly described the data, the output $\Delta 2$ would have population mean $0$. The observed population mean for $\Delta 2$ is $0.01047$, which means that either: 1) there is at least one confounding variable that affects a student's cumulative GPA, or that 2) the term dependancy of a student's cumulative GPA is not linear. I am personally more inclined to believe the latter, because GPA is bounded on the interval $[0,4]$, and so cannot perfectly follow an affine path over an arbitrary number of semesters unless the slope were exactly zero. That said, for the mean student taking the mean number of terms the models are pretty good. Now that we know the overall mean value for $\Delta 2$, we can use the one sample t-test and bootstrap confidence intervals with $\alpha = 0.01$ to determine whether a given faculty member had a mean positive or negative on their students final cumulative GPA's. I want to be clear: the $\Delta 2$ statistic I've created is not immune to harsh/lenient grading by the first professor, because it is measured assuming that the first observed GPA value was an accurate intercept for the linear mixed effects model. That said, the model attempts to correct for individual student variance by starting the affine from the first observed GPA value.

In order to apply a one sample t-test using the test statistic $t = \frac{\bar{x} - \mu}{s_e}$, we must have 3 things: 
1) A sample mean. In my code I have labeled this as a variable of Delta2.Data called Mean.Delta2. It is the mean deviation from the course corrected linear mixed model experienced by all the students that started with the observed faculty member. 
2) A sample standard error. This is calculated as the sample standard deviation of Delta2 values divided by the square root of the number of students that started with the observed faculty member.
3) A population mean or estimate for population mean. In our case we have obtained an estimate for population mean because of all the filtration that was necessary. 

The one sample t-test is carried out for all faculty members that had at least 3 students start with them. Significance is determined by whether the absolute value of the observed t statistic surpassed the $0.95$ t quantile with degrees of freedom equal to the number of students that started with the faculty minus one. Results of the one sample t-test are stored in the dataframe Delta2.Data3. In total, there were `r length(Prof.Qualities)` faculty with significant effects on future cumulative GPA for the students that had them first out of the original `r length(unique(Gen_Data$`Faculty Random ID`))` faculty members. Of those `r length(Prof.Qualities)`, `r length(Prof.Qualities[Prof.Qualities == "Good"])` faculty made a positive difference in future cumulative GPA, while `r length(Prof.Qualities)-length(Prof.Qualities[Prof.Qualities == "Good"])` made a $\textit{negative}$ difference in future cumulative GPA. These numbers are very close because they are measured from whether the faculty members students that started with them did better or worse than the applicable of the 23 linear mixed-effects models suggested they would do.  

Let's summarize the results from this analysis. Once again, in the following when I reference points, I refer to the difference between the expected final cumulative GPA and the observed final cumulative GPA as predicted by the linear mixed-effects model for students that started in the relevant course. In a nutshell, the professors for which I could distill inference had a range of effects from `r Delta2.Data3 %>% filter(significant == TRUE) %>% pull(Mean.Delta2) %>% min()` cumulative GPA points to `r Delta2.Data3 %>% filter(significant == TRUE) %>% pull(Mean.Delta2) %>% max()` with standard deviation `r Delta2.Data3 %>% filter(significant == TRUE) %>% pull(Mean.Delta2) %>% sd()`. The mean effect for those professors that had significant effect was `r Delta2.Data3 %>% filter(significant == TRUE) %>% pull(Mean.Delta2) %>% mean()` points. I have graphed the effects below.
```{r Delta2 Plots, warning=FALSE}
##Course Heights for scatterplot
Course.Heights <- tibble(`Course Code` = unique(Filtered.Data5$First.Course)) %>%
                    arrange(`Course Code`) %>%
                      cbind(tibble(Height = seq(-0.35, 0.35, by = 0.7/18)))

##Boxplots of Difference between Expected and Observed Cumulative GPA as predicted by linear mixed effects models for each course, colored by course code, for students that obeyed filtration assumptions
Delta2.Data %>%
  dplyr::select(-First.Prof) %>%
    right_join(Gen_Data9) %>%
      group_by(`Student Random ID`) %>%
        slice(n()) %>%
          filter(!is.na(First.Prof)) %>%
            dplyr::select(First.Course, Delta2) %>%
              ungroup() %>%
                ggplot(aes(color = First.Course)) +
                geom_boxplot(aes(x = Delta2), alpha = 0.9) +
                labs(x = "Delta2 (0-4 scale)", y = "Class", color = "Course Code", title = "Boxplots of Delta2 for each Individual Student that Passed\nFiltration, Colored by Course Code.") +
                scale_x_continuous(limits = c(-4,4))

##Histogram of significant mean professor effects onto final cumulative GPA for students that obeyed filtration assumptions.
Delta2.Data3 %>%
  filter(significant == TRUE) %>%
    dplyr::select(First.Prof, Mean.Delta2, standard.error) %>%
      mutate(Hist.Colors = factor(if_else(Mean.Delta2 < mean(pull(filter(Delta2.Data3, significant == TRUE), Mean.Delta2)), "green", "red"))) %>%
        ggplot() +
        geom_histogram(aes(x = Mean.Delta2, fill= Hist.Colors), bins = 22) +
        labs(x = "Mean Delta2 (0-4 scale) among those students whom started with a professor and passed filtration", y = "Count", title = "Histogram of SIGNIFICANT Mean Professor Delta2 Effects, Filled by Effect\nPolarity from the Mean") +
        theme(legend.position = "none")

##Histogram of ALL mean professor effects onto final cumulative GPA for students that obeyed filtration assumptions. This graph is just to put the previous one in context, not for inference.
Delta2.Data3 %>%
    dplyr::select(First.Prof, Mean.Delta2, standard.error) %>%
      mutate(Hist.Colors = factor(if_else(Mean.Delta2 < overall.mean.Delta2, "green", "red"))) %>%
        ggplot() +
        geom_histogram(aes(x = Mean.Delta2, fill= Hist.Colors), bins = 22) +
        labs(x = "Mean Delta2 (0-4 scale) among those students whom started with a professor and passed filtration", y = "Count", title = "Histogram of ALL Mean Professor Delta2 Effects, Filled by Effect\nPolarity from the Mean") +
        theme(legend.position = "none")

##Normal probability plot for Delta2
qqnorm(pull(filter(Delta2.Data3, significant == TRUE), Mean.Delta2), main = "Normal Q-Q Plot for Significant Mean Professor Delta2 Effects")

##Course Mean Delta2 Values for all students that passed filtration assumptions
Course.Delta2.Means <- Filtered.Data5 %>%
                        ungroup() %>%
                          group_by(First.Course) %>%
                            summarise(Course.Mean.Delta2 = mean(Delta2), Course.Sd.Delta2 = sd(Delta2))

##Scatterplot for only significant mean Delta2 values as measured by a one-sample t test onto each of the 19 strata
Filtered.Data5 %>%
  ungroup() %>%
    group_by(`Student Random ID`) %>%
      slice(n()) %>%
        select(`Student Random ID`, First.Course, First.Prof, Delta2, Course.Code.Mean.GPA) %>%
          ungroup() %>%
            group_by(First.Prof, First.Course) %>%
              summarise(Mean.Delta2 = mean(Delta2, na.rm = TRUE), n = n()) %>%
                filter(n >= 3) %>%
                  left_join(Course.Delta2.Means, by = "First.Course") %>%
                    mutate(requisite.tval = qt(0.95, n-1), observed.tval = abs(Mean.Delta2 - Course.Mean.Delta2)/(Course.Sd.Delta2/sqrt(n))) %>%
                      mutate(significant = if_else(observed.tval > requisite.tval, TRUE, FALSE)) %>%
                        filter(significant == TRUE) %>%
                          rename(`Faculty Random ID` = First.Prof, `Course Code` = First.Course) %>%
                            ungroup() %>%               
                              left_join(Course.Heights, by = "Course Code") %>%
                                ggplot() +
                                geom_point(aes(x = Mean.Delta2, y = Height, color = `Course Code`, size = n), position = position_jitter(height = 0.005)) +
                                labs(x = "Mean Delta2 (0-4 scale) among those students whom started\nwith a professor in a stratum", y = "Class", n = "Number of Students", color = "Course Code", title = "Scatterplot of Mean Faculty Delta2 Effects by Course\nfor SIGNIFICANT Courses") +
                                scale_x_continuous(limits = c(-2,2))
           
##Scatterplot of ALL mean Delta2 values for each of the 19 strata
Filtered.Data5 %>%
  ungroup() %>%
    group_by(`Student Random ID`) %>%
      slice(n()) %>%
        select(`Student Random ID`, First.Course, First.Prof, Delta2, Course.Code.Mean.GPA) %>%
          ungroup() %>%
            group_by(First.Prof, First.Course) %>%
              summarise(Mean.Delta2 = mean(Delta2, na.rm = TRUE), n = n()) %>%
                filter(n >= 3) %>%
                  left_join(Course.Delta2.Means, by = "First.Course") %>%
                    rename(`Faculty Random ID` = First.Prof, `Course Code` = First.Course) %>%
                      ungroup() %>%               
                        left_join(Course.Heights, by = "Course Code") %>%
                          ggplot() +
                          geom_point(aes(x = Mean.Delta2, y = Height, color = `Course Code`, size = n), position = position_jitter(height = 0.005)) +
                          labs(x = "Mean Delta2 (0-4 scale) among those students whom started\nwith a professor in a stratum", y = "Class", n = "Number of Students", color = "Course Code", title = "Scatterplot of Mean Faculty Delta2 Effects by Course\nfor ALL Courses") +
                          scale_x_continuous(limits = c(-2,2))


##Vector containing the mean number of students that a professor taught for a single course, used in below paragraphs   
Mean.Students <- Filtered.Data5 %>%
                  ungroup() %>%
                    group_by(`Course Code`, `Faculty Random ID`) %>%
                      count() %>%
                        ungroup() %>%
                          group_by(`Faculty Random ID`) %>%
                            summarise(Mean.Students = mean(n)) %>%
                              pull(Mean.Students)

##Statistics about Mean.Students vector
##mean(Mean.Students) is the mean number of students taught by a single faculty member for a single course code.
##sd(Mean.Students) is the standard deviation of the number of students taught by a single faculty member for a single course code.



```
The graph of all mean differences (including professors without significant effect) is included to clarify why a dip exists in the histogram of only significant mean differences. By the nature of the beast non-significant mean differences occur around the mean value of differences in final cumulative GPA, which is why there seems to be a missing bin in the histogram of significant effects. The distribution of this random variable is quite Gaussian, as can be seen in the probability plot above and the overall shape of the histograms. 

  The boxplot I have included is a plot of the individual student's $\Delta 2$ values in the 19 strata wherein at least 30 students started in the course. The courses with more students had a wider range of student outcomes as would be expected. There is no IQR for a single course that is drastically different from any other. This is also not surprising because the linear mixed-effects models take the outcome of the mean student to be the expected value, which invariably causes the mean difference for each course before filtration to be zero. The variation observed by our filtration specifications may simply be random noise. One notable course that may be of interest is CHE-1520, the filtered students of which had an unusually high number of positive outcomes. This may just be variance, because CHE-1520 only had `r Delta2.Data %>% right_join(Gen_Data9, by = "Student Random ID") %>% group_by(`Student Random ID`) %>% slice(n()) %>% ungroup() %>% group_by(First.Course) %>% count() %>% filter(First.Course == "CHE-1520") %>% pull(n)` students start in the course, which is low with respect to the mean of `r Delta2.Data %>% right_join(Gen_Data9, by = "Student Random ID") %>% group_by(`Student Random ID`) %>% slice(n()) %>% ungroup() %>% group_by(First.Course) %>% count() %>% filter(n >= 30) %>% pull(n) %>% mean()` students. 
  
  The first scatterplot contains the mean $\Delta 2$ values for the professors the students had first. The courses which the professors taught are separated and then checked for significance at the $\alpha = 0.05$ level. Each professor may have taught several different types of courses, and so their mean $\textit{for each course}$ is represented as a value in the boxplot for that course. Because the average faculty member taught `r mean(Mean.Students)` with a standard deviation of `r sd(Mean.Students)`, it is expected that many faculty-courses will not have enough data to prove significant. Indeed,  
  
  By comparison with the previous boxplot, we can gain some insight into the distribution of the $\Delta 2$ values. For example, looking at  CHE-1520, it seems that the students that started in CHE-1520 really did have a higher future cumulative GPA, as the mean $\Delta 2$ values for each of the five faculty that taught at least one CHE-1520 course are all above 0. It is important to note that this is the only case of all-positive $\Delta 2$ values on this plot. However, none of the t values for these faculty teaching this course d met the required $0.95$ quantile, and so we cannot significantly indicate this result as real.

Now we will bootstrap the individual values of difference between expected and observed final cumulative GPA for each professor as an alternative significance test, and we will note the number of professors whose significance changed between experiments. This will determine our confidence in the initial ranking.


```{r}
##Get that boot nice and strapped for each professor, then record those that had 


```



```{r}
##Use \Delta as predictor, but make sure to adjust \Delta for student.term


```


Try parallel processing - students can take multiple professors simultaneously

2) Does early exposure to mathematics predict / influence future performance in/out of major? Vice Versa?

  Early exposure difficult to define. Further analyse course code models
  

```{r}
##First Course in department Tracker

      

  ## FIRST TEACHER MATH:   Assign math points

First.Math.Data <- Gen_Data %>%
                    arrange(`Student Random ID`, Student.Term) %>%
                      group_by(`Student Random ID`) %>% 
                        filter(Department == "MAT") %>%
                          slice(1)


  ## FIRST TEACHER MATH:   Assign chemistry points
  
  
  ## FIRST TEACHER CHEM:   Assign chem points
  
  ## FIRST TEACHER CHEM:   Assign math points
  
  
  
  
  
  ## Here I check the rest of the profs, and assign them points for OUT OF MAJOR classes.
  
  ## Here I check the rest of the profs, and assign them points for IN MAJOR classes.
  
  
  


```

```{r}


```


2.5) How do individual professors affect the number of courses a student will take in major adjusted for course?



3) Do grades generally improve, worsen, or remain constant?





4) Do some teachers have significantly higher Withdraw rates than other professors? (p = .01)
  - Which courses have significantly higher withdraw rates?
  - Do the professors with significantly higher/lower withdraw rates match up with the professors rated "good"/"poor" by our Cum.GPA and Delta analyses?


```{r Professor Withdraw Tracker}
##Counts the proportion of withdraws per course that a professor teaches by class size. Compares to expected values.
Withdraws.Data <- Gen_Data  %>%
                    arrange(`Class Tracker`) %>%
                      group_by(`Course Code`, `Faculty Random ID`) %>%
                        filter(is.na(`GPA Assigned`)) %>%
                          count() %>%
                            arrange(`Faculty Random ID`) %>%
                              rename(n_withdraws = n)

          
Total <- Gen_Data  %>%
           arrange(`Class Tracker`) %>%
              group_by(`Course Code`, `Faculty Random ID`) %>%
                count() %>%
                  arrange(`Faculty Random ID`) %>%
                    rename(total_students = n)

Gen_Data_withdraw_prop <- length(Gen_Data$`GPA Assigned`[is.na(Gen_Data$`GPA Assigned`)])/n

Withdraws.Data <- left_join(Withdraws.Data, Total, by = c("Course Code", "Faculty Random ID")) %>%
                    mutate(observed_withdraw_prop = n_withdraws/total_students, expected_withdraws = Gen_Data_withdraw_prop*total_students)
```



```{r}
# Create models and plots of withdraws based on a couple different inputs.
Course.Code.withdraws.model <- lmer(n_withdraws ~ total_students + (1|`Course Code`), data = Withdraws.Data)
summary(Course.Code.withdraws.model)



##Visualization of effect of `Course Code` on n_withdraws using 10^3 bootstrap resamples
plotREsim(REsim(withdraws.model, n.sims = 10^3))

##plot(withdraws.model)


##Do I need the confint? Is that even useful?
withdraw.conf <- confint(withdraws.model, oldNames = FALSE, level = 0.95)


Plot.Data1 <- Withdraws.Data %>%
                group_by(`Faculty Random ID`) %>%
                  summarise(total_withdraws = sum(n_withdraws), total_students = sum(total_students)) %>%
                    arrange(`Faculty Random ID`)
##I'll go ahead and assign total withdraw points to profs right now before proceeding with graphing



Plot.Data1 %>%
  ggplot(aes(x = total_withdraws, y = total_students)) +
  geom_point(aes(color = factor(`Faculty Random ID`))) + 
  geom_smooth(color = "purple") +
  geom_smooth(method = "lm", color = "red") +
  theme(legend.position = "none") +
  labs(x = "Total withdraws", y = "Total students", title = "Total withdraws vs. total students, ")  
  
 ## geom_smooth(method = "lm", color = "red") +

##The standard errors of geom_smooth() and geom_smooth(method = "lm) overlap at almost all points, so it seems reasonable to assume that total withdraws vs total students can be validly represented by a linear model. I will do that presently.


```

```{r}
##total withdraws prop, number of students per prof
Points.Tracker <- arrange(Points.Tracker, Professors)
for(i in 1:length(Points.Tracker$Professors)){
  Points.Tracker$Total.Withdraw.Prop[i] <- Plot.Data1$total_withdraws[i]/Plot.Data1$total_students[i]
  Points.Tracker$Total.Students[i] <- Plot.Data1$total_students[i]
}
```


5) What is the mean number of different courses a prof teaches? What is the mean number of majors a prof teaches? Other interesting statistics?

How do individual professors vary in their ability teach various courses?

```{r}
Gen_Data <- Gen_Data %>%
              group_by(`Course Code`) %>%
                summarise(Course.Mean.GPA = mean(`GPA Assigned`, na.rm = TRUE)) %>%
                  right_join(Gen_Data, by = "Course Code")                    
```





```{r Course Lookup Table}
## This is a course lookup table
Course.Credits
```







